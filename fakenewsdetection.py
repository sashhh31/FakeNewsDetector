# -*- coding: utf-8 -*-
"""FakeNewsDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lGlsTPVeC3XlyEJ9BOmqRJGzFaJ7wrWs
"""

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from google.colab import files
from nltk.stem import PorterStemmer
import nltk
from nltk.stem import WordNetLemmatizer

uploaded = files.upload()

df_fake = pd.read_csv('Fake.csv')
df_true = pd.read_csv('True.csv')

# Add labels
df_true['label'] = 0  # Real news -> label 0
df_fake['label'] = 1  # Fake news -> label 1

# Combine the datasets
df = pd.concat([df_true, df_fake], axis=0)
df = df.sample(frac=1).reset_index(drop=True)  # Shuffle the dataset

# Check the first few rows
df.head()

def clean_text(text):
    text = re.sub(r"http\S+", "", text)  # Remove URLs
    text = re.sub(r"[^a-zA-Z]", " ", text)  # Remove punctuation
    text = text.lower()  # Convert to lowercase
    text = re.sub(r"\s+", " ", text).strip()  # Remove extra whitespaces
    return text

nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()
df['text'] = df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))
# Apply text cleaning
df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 2]))

# Drop missing values
df = df.dropna()

# Check cleaned data
df.head()

X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)

# Feature Extraction using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Model Building - Logistic Regression
lr_model = LogisticRegression()

# Model Building - Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)

# Ensemble - Voting Classifier
voting_model = VotingClassifier(estimators=[('lr', lr_model), ('dt', dt_model)], voting='soft')

# Train the ensemble model
voting_model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = voting_model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Ensemble Model Accuracy: {accuracy}")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

